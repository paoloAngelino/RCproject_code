{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bf24bb4-d77f-476d-9820-3150a572b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.packages as rpackages\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sb\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "from keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import random\n",
    "import rpy2.robjects as ro\n",
    "from rpy2 import robjects\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pandas as pd\n",
    "\n",
    "# adata = sc.read('/tmp/work/RCproject_code/sce_export.h5ad')\n",
    "epoch_count = 0\n",
    "\n",
    "# Enable automatic conversion between R objects and pandas DataFrames\n",
    "pandas2ri.activate()\n",
    "\n",
    "#exclude partial\n",
    "# adata = adata[~adata.obs['Response'].isin(['partial']), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cb21723-a836-4597-927b-04267ec8d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = 0.1\n",
    "dropout_rate = 0.3 #0.1\n",
    "balance = True\n",
    "l2_reg = 0.2\n",
    "batch_size = 16  #determines how many samples are processed per batch, each epoch will process multiple batches\n",
    "# learning_rate = 0.00001\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100000\n",
    "report_frequency = 1\n",
    "accuracy_threshold = 0.9  #currently not used\n",
    "auc_threshold = 0.90\n",
    "clipnorm = 2.0\n",
    "simplifly_categories = True\n",
    "holdout_size = 0.5\n",
    "\n",
    "use_gene_list = True\n",
    "current_gene_list = 'de_intersect_plus_bulk_genes'#'sig9_0.05'\n",
    "\n",
    "PCA_reduce = False\n",
    "n_comp_PCA = 16\n",
    "\n",
    "multiplier = 3 #0.91 performance with 3\n",
    "\n",
    "#dynamic learning rate parameters\n",
    "\n",
    "lr_dict = {\n",
    "    0.6:  0.005,\n",
    "    0.7:  0.001,\n",
    "    0.8:  0.0005,\n",
    "    0.85: 0.0001,\n",
    "    0.88: 0.00005,\n",
    "    0.89: 0.00001,\n",
    "    0.9:  0.000005,\n",
    "    0.91: 0.000001,\n",
    "    0.92: 0.0000005\n",
    "}\n",
    "\n",
    "auc_thresholds = [0.6, 0.7, 0.8, 0.85, 0.88,0.89,0.90,0.91,0.92]  # AUC values at which the learning rate should be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f6015e9-d6a4-4680-b92d-3303d6f13915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['meta', 'DE4', 'DEall', 'meta_intersect_unionDE', 'de_intersect', 'de_intersect_plus_bulk_genes', '5k', 'CV', 'CV300', 'CV300_4MA', 'Boruta_4MA', 'Boruta_6', 'CVBig', 'final300', 'final350', 'final', 'sig_4_6_0.05', 'sig_4_6_0.1', 'sig9_0.05', 'sig9_0.01', 'sig9', 'GEOMX_4_6_0.05_'])\n"
     ]
    }
   ],
   "source": [
    "# Load the RDS file\n",
    "rds_path = '/tmp/work/RCproject/gene_lists.rds'\n",
    "rds_data = r.readRDS(rds_path)\n",
    "\n",
    "# Extract the names of the lists and their contents\n",
    "gene_lists = {}\n",
    "for name, item in zip(rds_data.names, rds_data):\n",
    "    # Each 'item' is a list associated with the 'name'\n",
    "    inner_list = list(item)  # Convert the inner R list to a Python list\n",
    "    gene_lists[name] = inner_list\n",
    "\n",
    "# Now `python_data` is a dictionary with names as keys and lists as values\n",
    "print(gene_lists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d29fdb4d-c7cc-4693-910f-ef519d59bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "# select a gene_list\n",
    "\n",
    "current_genes = gene_lists[current_gene_list]\n",
    "print(len(current_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2db574c6-719c-4623-a50d-a80053d5eb57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts DataFrame:\n",
      "        GSM3899156_GSE133057  GSM3899157_GSE133057  GSM3899158_GSE133057  \\\n",
      "A1CF                0.057669             -0.027535              0.447468   \n",
      "A2M                 0.392288             -0.233300             -0.691535   \n",
      "A2ML1              -0.448972             -0.560902             -0.670516   \n",
      "A4GALT             -0.218099              0.224682             -0.247762   \n",
      "AAAS               -1.148204             -0.252932              0.053839   \n",
      "\n",
      "        GSM3899159_GSE133057  GSM3899160_GSE133057  GSM3899161_GSE133057  \\\n",
      "A1CF                0.045675              0.014587              1.406735   \n",
      "A2M                 0.293834             -1.091569             -0.816868   \n",
      "A2ML1               0.532968              0.516362              1.266745   \n",
      "A4GALT             -1.663294             -0.673025              0.513021   \n",
      "AAAS                0.442668              0.006890              0.582186   \n",
      "\n",
      "        GSM3899162_GSE133057  GSM3899163_GSE133057  GSM3899164_GSE133057  \\\n",
      "A1CF               -0.390043             -0.141597             -0.939894   \n",
      "A2M                 0.115628              0.384196              1.236704   \n",
      "A2ML1               1.132630              0.017735              0.335514   \n",
      "A4GALT              0.452215              1.025558              1.812865   \n",
      "AAAS                0.456027              0.470222             -0.351307   \n",
      "\n",
      "        GSM3899165_GSE133057  ...  GSM6390453_GSE209746  GSM6390454_GSE209746  \\\n",
      "A1CF                0.496517  ...              0.481642             -0.494055   \n",
      "A2M                 0.721205  ...              1.271784              2.545357   \n",
      "A2ML1               0.367068  ...             -1.763592             -1.603974   \n",
      "A4GALT             -0.386278  ...             -0.792048             -0.029957   \n",
      "AAAS                0.276047  ...              0.178485              0.211358   \n",
      "\n",
      "        GSM6390455_GSE209746  GSM6390456_GSE209746  GSM6390457_GSE209746  \\\n",
      "A1CF                0.692194              0.141950              0.554797   \n",
      "A2M                 1.705187              2.176357              2.173685   \n",
      "A2ML1              -1.897987             -1.911380             -1.666886   \n",
      "A4GALT             -0.723102             -0.532311             -0.472129   \n",
      "AAAS                0.189983              0.189037             -0.142190   \n",
      "\n",
      "        GSM6390458_GSE209746  GSM6390459_GSE209746  GSM6390460_GSE209746  \\\n",
      "A1CF                0.756641              0.757147              0.263922   \n",
      "A2M                 1.465240              1.147636              2.230243   \n",
      "A2ML1              -1.513177             -1.772573             -1.714675   \n",
      "A4GALT             -1.560049             -1.291245             -0.483064   \n",
      "AAAS               -0.114270              0.214479             -0.019179   \n",
      "\n",
      "        GSM6390461_GSE209746  GSM6390462_GSE209746  \n",
      "A1CF                0.054849              1.130573  \n",
      "A2M                 2.129601              1.589073  \n",
      "A2ML1              -2.031892             -1.777141  \n",
      "A4GALT             -0.167779             -0.986447  \n",
      "AAAS                0.088624             -0.014329  \n",
      "\n",
      "[5 rows x 450 columns]\n",
      "\n",
      "Metadata DataFrame:\n",
      "                     Response  TRG therapy Treatment Platform      batch\n",
      "GSM3899156_GSE133057      yes  1,2     CRT       pre  GPL6102  GSE133057\n",
      "GSM3899157_GSE133057  partial    3     CRT       pre  GPL6102  GSE133057\n",
      "GSM3899158_GSE133057      yes  1,2     CRT       pre  GPL6102  GSE133057\n",
      "GSM3899159_GSE133057  partial    3     CRT       pre  GPL6102  GSE133057\n",
      "GSM3899160_GSE133057      yes  1,2     CRT       pre  GPL6102  GSE133057\n"
     ]
    }
   ],
   "source": [
    "#import the data\n",
    "\n",
    "# Function to read RDS file and extract counts and metadata\n",
    "def read_rds_to_matrix_and_metadata(file_path):\n",
    "    # Load the RDS file in R\n",
    "    ro.r(f\"sce <- readRDS('{file_path}')\")\n",
    "\n",
    "    # Extract count data (assumed to be stored in assays)\n",
    "    counts = ro.r('assay(sce, \"scalelogcounts\")')\n",
    "    # Extract row (gene) and column (cell) names\n",
    "    gene_names = ro.r('rownames(sce)')\n",
    "    cell_names = ro.r('colnames(sce)')\n",
    "    \n",
    "    # Convert to a NumPy array\n",
    "    counts_np = ro.conversion.rpy2py(counts)\n",
    "\n",
    "    # Convert the counts matrix to a pandas DataFrame\n",
    "    counts_df = pd.DataFrame(counts_np, index=gene_names, columns=cell_names)\n",
    "\n",
    "    # Extract metadata from colData and convert to a pandas DataFrame directly\n",
    "    metadata = ro.r('as.data.frame(colData(sce))')  # Get the colData as an R data frame\n",
    "    metadata_df = pd.DataFrame(metadata)  # Convert R data frame to pandas DataFrame directly\n",
    "\n",
    "    return counts_df, metadata_df\n",
    "\n",
    "# Usage example\n",
    "file_path = '/tmp/work/RCproject/GEO_singlecellexperiment.rds'\n",
    "counts_df, metadata_df = read_rds_to_matrix_and_metadata(file_path)\n",
    "\n",
    "# Display the results\n",
    "print(\"Counts DataFrame:\")\n",
    "print(counts_df.head())  # Show the first few rows of the counts DataFrame\n",
    "print(\"\\nMetadata DataFrame:\")\n",
    "print(metadata_df.head())  # Show the first few rows of the metadata DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6583f32-fa79-4bc3-b575-e0cd98b82eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gene_list:\n",
    "    counts_df = counts_df.loc[current_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcdfc63c-ef87-4636-a16f-89c97a7568db",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_metadata_df = metadata_df[~metadata_df['Response'].isin(['partial'])].copy()\n",
    "\n",
    "row_names = filtered_metadata_df.index.tolist()  # Convert index to a list\n",
    "\n",
    "filtered_counts_df = counts_df[row_names].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc7a6582-5a3a-4174-83e2-6e0d55f0d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = metadata_df[~adata.obs['Response'].isin(['partial']), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f915216b-b70c-4c2d-a76d-a43fad99f14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410,)\n",
      "(410,)\n"
     ]
    }
   ],
   "source": [
    "# generate numerical values for each batch category\n",
    "# set up categories variable\n",
    "\n",
    "# categories_technology = adata.obs['batch']\n",
    "categories_technology = filtered_metadata_df['batch']\n",
    "\n",
    "#collpse the categories to microARRAY vs sequencing\n",
    "\n",
    "if simplifly_categories:\n",
    "    category_map = {'GSE133057': 'micro', 'GSE145037': 'micro', 'GSE150082': 'micro','GSE190826':'seq','GSE209746':'seq',\n",
    "                    'GSE45404_GPL1': 'micro', 'GSE45404_GPL2': 'micro', 'GSE93375': 'micro','GSE94104': 'micro'}\n",
    "    categories_technology = np.vectorize(category_map.get)(categories_technology)\n",
    "    \n",
    "# Create a LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit and transform the categories to integers\n",
    "numerical_categories_technology = label_encoder.fit_transform(categories_technology)\n",
    "print(numerical_categories_technology.shape)\n",
    "\n",
    "#do the same for the response variable\n",
    "\n",
    "# categories_outcome = adata.obs['Response']\n",
    "categories_outcome = filtered_metadata_df['Response']\n",
    "\n",
    "numerical_categories_outcome = label_encoder.fit_transform(categories_outcome)\n",
    "print(numerical_categories_technology.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8664a4b-9266-4cf4-b692-2c0d4ed39a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology frequencies\n",
      "0    209\n",
      "1    201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome frequencies\n",
      "0    267\n",
      "1    143\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_counts = pd.Series(numerical_categories_technology).value_counts()\n",
    "print('Technology frequencies')\n",
    "print(frequency_counts)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Outcome frequencies')\n",
    "frequency_counts = pd.Series(numerical_categories_outcome).value_counts()\n",
    "print(frequency_counts)\n",
    "\n",
    "unique_combinations_array = (numerical_categories_outcome + (numerical_categories_technology+1)*2)-2\n",
    "\n",
    "np.unique(unique_combinations_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056bf30b-3e46-4f4c-a4af-84b512dacb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming filtered_metadata_df is your filtered DataFrame\n",
    "filtered_metadata_df.loc[:, 'numerical_categories_technology'] = numerical_categories_technology\n",
    "filtered_metadata_df.loc[:, 'numerical_categories_outcome'] = numerical_categories_outcome\n",
    "filtered_metadata_df.loc[:, 'combination_tech_outcome'] = unique_combinations_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b4334e7-f769-4c03-937b-e148872ee0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizaiton\n",
    "# gene_expression_data = adata.layers['scalelogcounts']\n",
    "\n",
    "gene_expression_data = filtered_counts_df.T\n",
    "\n",
    "#Min-max normalization\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "gene_expression_data = scaler.fit_transform(gene_expression_data)\n",
    "\n",
    "number_genes = gene_expression_data.shape[1]\n",
    "input_dim = number_genes\n",
    "\n",
    "if PCA_reduce:\n",
    "# Initialize PCA and fit it to X_train\n",
    "    n_components = n_comp_PCA  # You can adjust this based on your data\n",
    "    pca = PCA(n_components=n_components)\n",
    "    gene_expression_data = pca.fit_transform(gene_expression_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b9e5d24-4d09-4086-ae32-4395f1d88172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 366)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expression_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49420799-06ca-4838-984e-e4fa9c61389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242.89348460298876\n",
      "178.45784195566702\n"
     ]
    }
   ],
   "source": [
    "print(sum(gene_expression_data[:,0]))\n",
    "print(sum(gene_expression_data[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d46fe7c-8faf-4f29-82f8-f2d00be059e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(gene_expression_data, filtered_metadata_df, test_size=test_set_size, random_state=1)\n",
    "\n",
    "y_train_outcome = y_train['numerical_categories_outcome']\n",
    "y_test_outcome = y_test['numerical_categories_outcome']\n",
    "\n",
    "y_train_tech = y_train['numerical_categories_technology']\n",
    "y_test_tech = y_test['numerical_categories_technology']\n",
    "\n",
    "y_train_comb = y_train['combination_tech_outcome']\n",
    "y_test_comb = y_test['combination_tech_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0f626da-39f7-418e-8e73-f267b981e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the input shape\n",
    "# # input_shape = (gene_expression_data.shape[1],)[0]  # Number of genes\n",
    "\n",
    "input_shape = (X_train.shape[1],)[0]  # Number of genes\n",
    "\n",
    "def build_outcome_classifier():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(input_shape,)))  # Input shape matches your data\n",
    "    \n",
    "    model.add(layers.Dense((512*multiplier),kernel_regularizer=tf.keras.regularizers.l2(l2_reg),kernel_initializer='he_normal'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))  # Leaky ReLU helps with vanishing gradients\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Dense((256*multiplier),kernel_regularizer=tf.keras.regularizers.l2(l2_reg),kernel_initializer='he_normal'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Dense((128*multiplier),kernel_regularizer=tf.keras.regularizers.l2(l2_reg),kernel_initializer='he_normal'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(layers.Dense((64*multiplier),kernel_regularizer=tf.keras.regularizers.l2(l2_reg),kernel_initializer='he_normal'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Dense((32),kernel_initializer='he_normal'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    # Output layer for binary classification with sigmoid activation\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f07cdd3d-9030-4220-93f4-f1bbf2e8713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "outcome_classifier = build_outcome_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a566cb12-0842-4253-9379-d32fdebb4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback-like function to adjust learning rate based on AUC\n",
    "def adjust_learning_rate_by_auc(epoch, model, X_test, y_test_outcome, lr_dict, auc_thresholds,test_auc):\n",
    "    # Get model's current learning rate\n",
    "    current_lr = tf.keras.backend.get_value(model.optimizer.lr)\n",
    "\n",
    "    # Adjust learning rate based on AUC thresholds\n",
    "    new_lr = current_lr\n",
    "    for threshold in auc_thresholds:\n",
    "        if test_auc >= threshold:\n",
    "            new_lr = lr_dict[threshold]\n",
    "    \n",
    "    # Set new learning rate\n",
    "    if new_lr != current_lr:\n",
    "        tf.keras.backend.set_value(model.optimizer.lr, new_lr)\n",
    "        #print(f\"Epoch {epoch + 1}: Adjusting learning rate to {new_lr:.6f}\")\n",
    "    \n",
    "    return test_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e85e8399-811c-42d2-8150-72318a156f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set up the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm = clipnorm)\n",
    "\n",
    "# determine the sample and batch size\n",
    "num_samples = math.floor(X_train.shape[0]* (1-holdout_size))  # number of samples used in each training epoch\n",
    "\n",
    "# batch_size = adata.shape[0]\n",
    "\n",
    "# Calculate the number of steps per epoch\n",
    "num_steps_per_epoch = num_samples // batch_size\n",
    "\n",
    "# Compile the outcome discriminator\n",
    "outcome_classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0ecf815-9b2c-4a7d-bd55-af6e2326a740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Outcome Loss: 0.7484279329126532, Average Accuracy: 0.5, Test AUC: 0.5000, Test Accuracy: 0.6341\n",
      "Epoch 100, Average Outcome Loss: 0.6667680035937916, Average Accuracy: 0.6193181818181818, Test AUC: 0.7513, Test Accuracy: 0.6585\n",
      "Epoch 200, Average Outcome Loss: 0.5096665160222487, Average Accuracy: 0.7556818181818182, Test AUC: 0.7769, Test Accuracy: 0.6829\n",
      "Epoch 300, Average Outcome Loss: 0.5236100364815105, Average Accuracy: 0.7443181818181818, Test AUC: 0.8051, Test Accuracy: 0.6829\n",
      "Epoch 400, Average Outcome Loss: 0.4396063170649789, Average Accuracy: 0.75, Test AUC: 0.8231, Test Accuracy: 0.7317\n",
      "Epoch 500, Average Outcome Loss: 0.3971788612279025, Average Accuracy: 0.7897727272727273, Test AUC: 0.8256, Test Accuracy: 0.7561\n",
      "Epoch 600, Average Outcome Loss: 0.31799676607955585, Average Accuracy: 0.8920454545454546, Test AUC: 0.8513, Test Accuracy: 0.7561\n",
      "Epoch 700, Average Outcome Loss: 0.32247735830870544, Average Accuracy: 0.8522727272727273, Test AUC: 0.8385, Test Accuracy: 0.6585\n",
      "Epoch 800, Average Outcome Loss: 0.5345580090175975, Average Accuracy: 0.7215909090909091, Test AUC: 0.8436, Test Accuracy: 0.6098\n",
      "Epoch 900, Average Outcome Loss: 0.2546336583115838, Average Accuracy: 0.8636363636363636, Test AUC: 0.8256, Test Accuracy: 0.8537\n",
      "Epoch 1000, Average Outcome Loss: 0.207385086200454, Average Accuracy: 0.8977272727272727, Test AUC: 0.8103, Test Accuracy: 0.7561\n",
      "Epoch 1100, Average Outcome Loss: 0.3969510265372016, Average Accuracy: 0.8068181818181818, Test AUC: 0.8256, Test Accuracy: 0.7805\n",
      "Epoch 1200, Average Outcome Loss: 0.32420076768506656, Average Accuracy: 0.8181818181818182, Test AUC: 0.8308, Test Accuracy: 0.8293\n",
      "Epoch 1300, Average Outcome Loss: 0.19548003578727896, Average Accuracy: 0.8806818181818182, Test AUC: 0.8179, Test Accuracy: 0.7805\n",
      "Epoch 1400, Average Outcome Loss: 1.3060830398039385, Average Accuracy: 0.6875, Test AUC: 0.8103, Test Accuracy: 0.6829\n",
      "Epoch 1500, Average Outcome Loss: 0.2785305225036361, Average Accuracy: 0.8579545454545454, Test AUC: 0.8154, Test Accuracy: 0.6098\n",
      "Epoch 1600, Average Outcome Loss: 0.22958304157311266, Average Accuracy: 0.8977272727272727, Test AUC: 0.8128, Test Accuracy: 0.7561\n",
      "Epoch 1700, Average Outcome Loss: 0.13715220987796783, Average Accuracy: 0.8977272727272727, Test AUC: 0.8103, Test Accuracy: 0.8293\n",
      "Epoch 1800, Average Outcome Loss: 0.09243898398496887, Average Accuracy: 0.9943181818181818, Test AUC: 0.8154, Test Accuracy: 0.8293\n",
      "Epoch 1900, Average Outcome Loss: 0.18929331817410208, Average Accuracy: 0.875, Test AUC: 0.8128, Test Accuracy: 0.8049\n",
      "Epoch 2000, Average Outcome Loss: 0.05951756882396611, Average Accuracy: 0.9886363636363636, Test AUC: 0.8051, Test Accuracy: 0.7561\n",
      "Epoch 2100, Average Outcome Loss: 0.388322425159541, Average Accuracy: 0.8238636363636364, Test AUC: 0.8026, Test Accuracy: 0.5854\n",
      "Epoch 2200, Average Outcome Loss: 0.09375164657831192, Average Accuracy: 1.0, Test AUC: 0.7769, Test Accuracy: 0.6829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(y_batch, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adjust labels shape for binary_crossentropy\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Perform the training step and collect gradients\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m outcome_loss, accuracy, classifier_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Accumulate gradients and losses\u001b[39;00m\n\u001b[1;32m     63\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m outcome_loss\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(data, outcome_labels)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(data, outcome_labels):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Forward pass through the outcome classifier\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         outcome_predictions \u001b[38;5;241m=\u001b[39m \u001b[43moutcome_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Compute the biological discriminator loss\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         outcome_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mbinary_crossentropy(outcome_labels, outcome_predictions)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:561\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    559\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1131\u001b[0m ):\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/sequential.py:413\u001b[0m, in \u001b[0;36mSequential.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m outputs \u001b[38;5;241m=\u001b[39m inputs  \u001b[38;5;66;03m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# the next layer.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py:511\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    494\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py:668\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 668\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    672\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[1;32m    673\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1131\u001b[0m ):\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:1042\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m     scale \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(scale, inputs\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 1042\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_normalization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_broadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_broadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_dtype \u001b[38;5;129;01min\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39mfloat16, tf\u001b[38;5;241m.\u001b[39mbfloat16):\n\u001b[1;32m   1051\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(outputs, inputs_dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/nn_impl.py:1594\u001b[0m, in \u001b[0;36mbatch_normalization\u001b[0;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   inv \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m scale\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;66;03m# Note: tensorflow/contrib/quantize/python/fold_batch_norms.py depends on\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;66;03m# the precise order of ops that are generated by the expression below.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mcast(inv, x\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m+\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m-> 1594\u001b[0m     offset \u001b[38;5;241m-\u001b[39m \u001b[43mmean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minv\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mmean \u001b[38;5;241m*\u001b[39m inv, x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:1090\u001b[0m, in \u001b[0;36mVariable._OverloadOperator.<locals>._run_op\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_op\u001b[39m(a, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1089\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor_oper(\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:584\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_value\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28;01mNone\u001b[39;00m, ignore_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:706\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    704\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    709\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    710\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    711\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    712\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    713\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    714\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:696\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    695\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 696\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:525\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    528\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_accuracy_list = []\n",
    "train_accuracy_list = []\n",
    "test_auc_list = []\n",
    "\n",
    "num_outcomes = len(np.unique(y_test_outcome))\n",
    "num_conditions = len(np.unique(unique_combinations_array))\n",
    "\n",
    "# Define the training step for only the outcome classifier\n",
    "def train_step(data, outcome_labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass through the outcome classifier\n",
    "        outcome_predictions = outcome_classifier(data)\n",
    "\n",
    "        # Compute the biological discriminator loss\n",
    "        outcome_loss = tf.keras.losses.binary_crossentropy(outcome_labels, outcome_predictions)\n",
    "        outcome_loss = tf.reduce_mean(outcome_loss)  # Average over the batch\n",
    "\n",
    "    # Compute gradients for the outcome classifier\n",
    "    classifier_grads = tape.gradient(outcome_loss, outcome_classifier.trainable_variables)\n",
    "    \n",
    "    # Calculate accuracy for the outcome classifier\n",
    "    predicted_outcome_labels = tf.cast(outcome_predictions > 0.5, tf.float32)  # Threshold at 0.5\n",
    "    outcome_labels_float = tf.cast(outcome_labels, tf.float32)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_outcome_labels, outcome_labels_float), tf.float32))\n",
    "\n",
    "    return outcome_loss, accuracy, classifier_grads\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0  # To accumulate losses\n",
    "    total_accuracy = 0.0  # To accumulate accuracy\n",
    "    accumulated_grads = [tf.zeros_like(var) for var in outcome_classifier.trainable_variables]  # Initialize gradient accumulator\n",
    "\n",
    "    # Split train data randomly, holding out a portion for generalization\n",
    "    X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(X_train, y_train, test_size=holdout_size, random_state=None)\n",
    "    y_train_comb_temp = y_train_temp['combination_tech_outcome']\n",
    "    y_train_temp = y_train_temp['numerical_categories_outcome']\n",
    "    \n",
    "    # Mini-batch training loop\n",
    "    for step in range(num_steps_per_epoch):\n",
    "        # Balance batches if necessary\n",
    "        batch_indices = []\n",
    "        if balance:\n",
    "            for condition in range(num_conditions):\n",
    "                condition_indices = np.where(y_train_comb_temp == condition)[0]\n",
    "                condition_batch_indices = np.random.choice(condition_indices, size=batch_size // num_conditions, replace=True)\n",
    "                batch_indices.append(condition_batch_indices)\n",
    "        else:\n",
    "            all_indices = np.arange(len(X_train_temp))\n",
    "            random_indices = np.random.choice(all_indices, size=batch_size, replace=True)\n",
    "            batch_indices.append(random_indices)\n",
    "        X_batch = X_train_temp[np.concatenate(batch_indices)]\n",
    "        #y_batch = y_train_temp[np.concatenate(batch_indices)]\n",
    "        y_batch = y_train_temp.iloc[np.concatenate(batch_indices)]\n",
    "        y_batch = tf.expand_dims(y_batch, axis=-1)  # Adjust labels shape for binary_crossentropy\n",
    "                \n",
    "        # Perform the training step and collect gradients\n",
    "        outcome_loss, accuracy, classifier_grads = train_step(X_batch, y_batch)\n",
    "        \n",
    "        # Accumulate gradients and losses\n",
    "        total_loss += outcome_loss.numpy()\n",
    "        total_accuracy += accuracy.numpy()\n",
    "        accumulated_grads = [acc_grad + grad for acc_grad, grad in zip(accumulated_grads, classifier_grads)]\n",
    "\n",
    "    # Average the accumulated gradients\n",
    "    averaged_grads = [grad / num_steps_per_epoch for grad in accumulated_grads]\n",
    "\n",
    "    # Apply averaged gradients to update model weights\n",
    "    optimizer.apply_gradients(zip(averaged_grads, outcome_classifier.trainable_variables))\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / num_steps_per_epoch\n",
    "    avg_accuracy = total_accuracy / num_steps_per_epoch\n",
    "\n",
    "    if epoch % report_frequency == 0:\n",
    "\n",
    "        #adjust the learning rate depending on test set performance\n",
    "        # adjust_learning_rate_by_auc(epoch, outcome_classifier, X_test_temp, y_test_temp['numerical_categories_outcome'], lr_dict, auc_thresholds)\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        outcome_predictions = outcome_classifier(X_test)\n",
    "        outcome_labels = tf.expand_dims(y_test_outcome, axis=-1)  # Reshape to match logits shape\n",
    "        outcome_labels_float = tf.cast(outcome_labels, tf.float32)\n",
    "    \n",
    "        # Calculate AUC\n",
    "        outcome_predictions_np = outcome_predictions.numpy().flatten()  # Convert predictions to numpy for roc_auc_score\n",
    "        outcome_labels_np = outcome_labels_float.numpy().flatten()  # Convert labels to numpy for roc_auc_score\n",
    "        test_auc = roc_auc_score(outcome_labels_np, outcome_predictions_np)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_outcome_labels = tf.cast(outcome_predictions > 0.5, tf.float32)  # Threshold at 0.5\n",
    "        outcome_labels_float = tf.cast(outcome_labels, tf.float32)\n",
    "        test_accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_outcome_labels, outcome_labels_float), tf.float32))\n",
    "    \n",
    "        # Store and print metrics\n",
    "        train_accuracy_list.append(avg_accuracy)\n",
    "        test_auc_list.append(test_auc)\n",
    "        test_accuracy_list.append(test_accuracy)\n",
    "        \n",
    "        if epoch % (report_frequency*100) == 0:\n",
    "            print(f'Epoch {epoch}, Average Outcome Loss: {avg_loss}, Average Accuracy: {avg_accuracy}, Test AUC: {test_auc:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        adjust_learning_rate_by_auc(epoch, outcome_classifier, X_test_temp, y_test_temp['numerical_categories_outcome'], lr_dict, auc_thresholds, test_auc)\n",
    "    \n",
    "        # Early stopping condition for AUC (if needed)\n",
    "        if test_auc > auc_threshold:  # Define auc_threshold as desired\n",
    "            print('Early stopping triggered based on AUC')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fa863-e671-4f71-8457-4918e949a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(test_auc_list))\n",
    "print(max(test_accuracy_list))\n",
    "print(max(train_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c2612-7184-44a1-9acd-9005348dfb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, plot the metrics\n",
    "\n",
    "frequency_counts = pd.Series(y_test_outcome).value_counts()\n",
    "test_chance_level = frequency_counts[0]/len(y_test_outcome)\n",
    "\n",
    "frequency_counts = pd.Series(y_train_outcome).value_counts()\n",
    "train_chance_level = frequency_counts[0]/len(y_train_outcome)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 6))\n",
    "\n",
    "x_values = np.arange(1, len(train_accuracy_list) + 1) * report_frequency\n",
    "\n",
    "# Plot train accuracy\n",
    "axs[0].plot(x_values, train_accuracy_list, label='Training Accuracy', color='blue')\n",
    "axs[0].axhline(train_chance_level, color='black',linestyle ='--')\n",
    "axs[0].set_title('Training set accuracy over epochs')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Training Accuracy')\n",
    "axs[0].grid()\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot test accuracay\n",
    "axs[1].plot(x_values, test_accuracy_list, label='Test Accuracy', color='orange')\n",
    "axs[1].axhline(test_chance_level, color='black',linestyle ='--')\n",
    "axs[1].set_title('Test set accuracy over epochs')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Test Accuracy')\n",
    "axs[1].grid()\n",
    "axs[1].legend()\n",
    "\n",
    "# Plot test accuracay\n",
    "axs[2].plot(x_values, test_auc_list, label='Test AUC', color='orange')\n",
    "# axs[2].axhline(0.5, color='black',linestyle ='--')\n",
    "axs[2].set_title('Test set AUC over epochs')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Test AUC')\n",
    "axs[2].grid()\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e4636-c91e-4a73-be93-40b6cc7cc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loop: Calculate ROC and AUC using continuous probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test_outcome, outcome_predictions)  # Use probabilities, not thresholded labels\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line for random guessing\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for ANN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84149f-2ef8-4123-bdb5-c23db0f40174",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train_outcome)\n",
    "\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]  # Probabilities for the positive class (class 1)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_outcome, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line for random guessing\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for random forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137e9c6-8f01-4e7b-bc2f-bb08b500f107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa81e2-5e22-4549-88c0-a52e1050e3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
